# VirtEngine VEID Identity Scoring Alert Rules
# Alerts for identity verification and ML scoring services

groups:
  # =============================================================================
  # VEID Scoring Availability
  # =============================================================================
  - name: veid_availability
    interval: 30s
    rules:
      # Scoring service unavailable
      - alert: VEIDScoringUnavailable
        expr: up{job="veid-scoring"} == 0
        for: 2m
        labels:
          severity: critical
          service: veid
          tier: tier1
        annotations:
          summary: "VEID scoring service unavailable"
          description: "VEID scoring instance {{ $labels.instance }} is down"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-unavailable"
          dashboard: "https://grafana.virtengine.com/d/veid-scoring"

      # Scoring success rate too low
      - alert: VEIDScoringSuccessRateLow
        expr: |
          (
            sum(rate(veid_scoring_requests_total{status="success"}[5m])) /
            sum(rate(veid_scoring_requests_total[5m]))
          ) < 0.995
        for: 5m
        labels:
          severity: high
          service: veid
          tier: tier1
        annotations:
          summary: "VEID scoring success rate below SLO"
          description: "Scoring success rate is {{ $value | humanizePercentage }}, target is 99.5%"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-low-success-rate"

  # =============================================================================
  # VEID Scoring Latency
  # =============================================================================
  - name: veid_latency
    interval: 30s
    rules:
      # Scoring latency too high
      - alert: VEIDScoringLatencyHigh
        expr: |
          histogram_quantile(0.95, 
            sum(rate(veid_scoring_duration_seconds_bucket[5m])) by (le)
          ) > 300
        for: 5m
        labels:
          severity: high
          service: veid
          tier: tier1
        annotations:
          summary: "VEID scoring P95 latency exceeds 5 minutes"
          description: "Scoring P95 latency is {{ $value | humanizeDuration }}, target is < 5 minutes"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-high-latency"

      # Scoring latency warning
      - alert: VEIDScoringLatencyWarning
        expr: |
          histogram_quantile(0.95, 
            sum(rate(veid_scoring_duration_seconds_bucket[5m])) by (le)
          ) > 180
        for: 10m
        labels:
          severity: warning
          service: veid
          tier: tier1
        annotations:
          summary: "VEID scoring P95 latency above 3 minutes"
          description: "Scoring P95 latency is {{ $value | humanizeDuration }}"

  # =============================================================================
  # ML Model Health
  # =============================================================================
  - name: veid_ml_model
    interval: 30s
    rules:
      # ML inference failure rate
      - alert: VEIDMLInferenceFailureRate
        expr: |
          rate(veid_ml_inference_errors_total[5m]) /
          rate(veid_ml_inference_total[5m]) > 0.01
        for: 5m
        labels:
          severity: high
          service: veid
          tier: tier1
        annotations:
          summary: "High ML inference failure rate"
          description: "ML inference error rate is {{ $value | humanizePercentage }}"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-ml-failures"

      # Non-deterministic inference detected
      - alert: VEIDNonDeterministicInference
        expr: increase(veid_inference_non_deterministic_total[10m]) > 0
        for: 1m
        labels:
          severity: critical
          service: veid
          tier: tier1
        annotations:
          summary: "CRITICAL: Non-deterministic ML inference detected"
          description: "{{ $value }} non-deterministic inference results detected - consensus may be affected"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-non-deterministic"

      # Model version mismatch between validators
      - alert: VEIDModelVersionMismatch
        expr: count(count by (model_version) (veid_ml_model_version)) > 1
        for: 5m
        labels:
          severity: critical
          service: veid
          tier: tier1
        annotations:
          summary: "CRITICAL: Model version mismatch between validators"
          description: "Multiple model versions detected across validators - consensus will fail"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-model-mismatch"

      # Model not loaded
      - alert: VEIDModelNotLoaded
        expr: veid_ml_model_loaded == 0
        for: 2m
        labels:
          severity: critical
          service: veid
          tier: tier1
        annotations:
          summary: "VEID ML model not loaded on {{ $labels.instance }}"
          description: "ML model is not loaded, scoring will fail"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-model-not-loaded"

  # =============================================================================
  # Verification Queue
  # =============================================================================
  - name: veid_queue
    interval: 30s
    rules:
      # Verification queue backlog
      - alert: VEIDQueueBacklog
        expr: veid_verification_queue_size > 100
        for: 10m
        labels:
          severity: warning
          service: veid
          tier: tier1
        annotations:
          summary: "VEID verification queue backlog"
          description: "{{ $value }} verifications pending in queue"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-queue-backlog"

      # Verification queue critical
      - alert: VEIDQueueCritical
        expr: veid_verification_queue_size > 500
        for: 5m
        labels:
          severity: high
          service: veid
          tier: tier1
        annotations:
          summary: "VEID verification queue critically high"
          description: "{{ $value }} verifications pending, users experiencing significant delays"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-queue-critical"

  # =============================================================================
  # Score Agreement (Consensus)
  # =============================================================================
  - name: veid_consensus
    interval: 30s
    rules:
      # Low score agreement rate
      - alert: VEIDScoreAgreementLow
        expr: |
          sum(rate(veid_score_agreement_total{result="match"}[10m])) /
          sum(rate(veid_score_agreement_total[10m])) < 0.99
        for: 5m
        labels:
          severity: warning
          service: veid
          tier: tier1
        annotations:
          summary: "Low VEID score agreement rate between validators"
          description: "Score agreement rate is {{ $value | humanizePercentage }}, target is > 99%"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-low-agreement"

      # High score difference
      - alert: VEIDHighScoreDifference
        expr: |
          histogram_quantile(0.95, 
            sum(rate(veid_score_difference_bucket[10m])) by (le)
          ) > 5
        for: 10m
        labels:
          severity: warning
          service: veid
          tier: tier1
        annotations:
          summary: "High VEID score difference between validators"
          description: "P95 score difference is {{ $value }} points"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-score-difference"

  # =============================================================================
  # Encryption & Security
  # =============================================================================
  - name: veid_security
    interval: 30s
    rules:
      # High decryption failure rate
      - alert: VEIDDecryptionFailureRate
        expr: |
          rate(veid_decryption_errors_total[5m]) /
          rate(veid_decryption_total[5m]) > 0.01
        for: 5m
        labels:
          severity: high
          service: veid
          tier: tier1
        annotations:
          summary: "High VEID data decryption failure rate"
          description: "Decryption error rate is {{ $value | humanizePercentage }}"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-decryption-failures"

      # Signature verification failures
      - alert: VEIDSignatureVerificationFailures
        expr: |
          rate(veid_signature_verification_errors_total[5m]) > 0.5
        for: 5m
        labels:
          severity: warning
          service: veid
          tier: tier1
        annotations:
          summary: "High VEID signature verification failure rate"
          description: "{{ $value }} signature verification failures per second"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-signature-failures"

  # =============================================================================
  # Resource Usage
  # =============================================================================
  - name: veid_resources
    interval: 30s
    rules:
      # High GPU memory usage
      - alert: VEIDGPUMemoryHigh
        expr: |
          (veid_gpu_memory_used_bytes / veid_gpu_memory_total_bytes) * 100 > 90
        for: 5m
        labels:
          severity: warning
          service: veid
          tier: tier1
        annotations:
          summary: "High GPU memory usage for VEID inference"
          description: "GPU memory usage is {{ $value | humanize }}% on {{ $labels.instance }}"
          runbook: "https://github.com/virtengine/virtengine/wiki/runbooks/veid-gpu-memory"

      # Model inference latency spike
      - alert: VEIDInferenceLatencySpike
        expr: |
          histogram_quantile(0.99, 
            sum(rate(veid_inference_duration_seconds_bucket[5m])) by (le)
          ) > 30
        for: 5m
        labels:
          severity: warning
          service: veid
          tier: tier1
        annotations:
          summary: "VEID inference latency spike"
          description: "P99 inference latency is {{ $value | humanizeDuration }}"
