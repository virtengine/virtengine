{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": { "type": "grafana", "uid": "-- Grafana --" },
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "description": "ML inference service metrics",
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "id": null,
  "links": [
    {
      "asDropdown": true,
      "icon": "external link",
      "includeVars": true,
      "keepTime": true,
      "tags": ["virtengine"],
      "targetBlank": false,
      "title": "VirtEngine Dashboards",
      "tooltip": "",
      "type": "dashboards",
      "url": ""
    }
  ],
  "panels": [
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "fieldConfig": { "defaults": { "unit": "ops" }, "overrides": [] },
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 0 },
      "id": 1,
      "targets": [
        { "expr": "rate(virtengine_ml_inference_requests_total[5m])", "legendFormat": "Requests", "refId": "A" }
      ],
      "title": "Inference Request Rate",
      "type": "timeseries"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "fieldConfig": { "defaults": { "unit": "s" }, "overrides": [] },
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 0 },
      "id": 2,
      "targets": [
        {
          "expr": "histogram_quantile(0.95, rate(virtengine_ml_inference_seconds_bucket[5m]))",
          "legendFormat": "P95",
          "refId": "A"
        },
        {
          "expr": "histogram_quantile(0.50, rate(virtengine_ml_inference_seconds_bucket[5m]))",
          "legendFormat": "Median",
          "refId": "B"
        }
      ],
      "title": "Inference Latency",
      "type": "timeseries"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "fieldConfig": { "defaults": { "unit": "percent", "min": 0, "max": 100 }, "overrides": [] },
      "gridPos": { "h": 8, "w": 6, "x": 0, "y": 8 },
      "id": 3,
      "options": { "orientation": "auto", "showThresholdLabels": false, "showThresholdMarkers": true },
      "targets": [
        {
          "expr": "rate(virtengine_ml_inference_errors_total[5m]) / rate(virtengine_ml_inference_requests_total[5m]) * 100",
          "refId": "A"
        }
      ],
      "title": "Inference Error Rate",
      "type": "gauge"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "fieldConfig": { "defaults": { "unit": "ops" }, "overrides": [] },
      "gridPos": { "h": 8, "w": 6, "x": 6, "y": 8 },
      "id": 4,
      "targets": [
        { "expr": "rate(virtengine_ml_inference_timeout_total[5m])", "legendFormat": "Timeouts", "refId": "A" }
      ],
      "title": "Inference Timeouts",
      "type": "timeseries"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "fieldConfig": { "defaults": { "unit": "short" }, "overrides": [] },
      "gridPos": { "h": 8, "w": 6, "x": 12, "y": 8 },
      "id": 5,
      "options": { "colorMode": "value", "graphMode": "none", "textMode": "auto" },
      "targets": [
        { "expr": "virtengine_ml_inference_queue_depth", "refId": "A" }
      ],
      "title": "Queue Depth",
      "type": "stat"
    },
    {
      "datasource": { "type": "prometheus", "uid": "${datasource}" },
      "fieldConfig": { "defaults": { "unit": "s" }, "overrides": [] },
      "gridPos": { "h": 8, "w": 6, "x": 18, "y": 8 },
      "id": 6,
      "targets": [
        {
          "expr": "histogram_quantile(0.95, rate(virtengine_ml_model_load_seconds_bucket[5m]))",
          "legendFormat": "P95",
          "refId": "A"
        }
      ],
      "title": "Model Load Latency",
      "type": "timeseries"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 39,
  "tags": ["virtengine", "ml"],
  "templating": {
    "list": [
      {
        "current": { "selected": false, "text": "Prometheus", "value": "Prometheus" },
        "hide": 0,
        "includeAll": false,
        "label": "Data Source",
        "multi": false,
        "name": "datasource",
        "options": [],
        "query": "prometheus",
        "queryValue": "",
        "refresh": 1,
        "regex": "",
        "skipUrlSync": false,
        "type": "datasource"
      }
    ]
  },
  "time": { "from": "now-6h", "to": "now" },
  "timepicker": {},
  "timezone": "browser",
  "title": "ML Inference",
  "uid": "ml-inference",
  "version": 1,
  "weekStart": ""
}
